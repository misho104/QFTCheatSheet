\documentclass[CheatSheet]{subfiles}
\begin{document}

\detailstyle
\section{Mathematics}
\subsection{Matrix exponential}
Excerpted from \S2 and \S5 of Hall 2015 \cite{hall2015}:
\begin{alignat}{2}
 &\ee^X := \sum_{m=0}^\infty \frac{X^m}{m!} \text{~~(converges for any $X$)},
\quad&
 &\log X := \sum_{m=1}^\infty (-1)^{m+1}\frac{(A-1)^m}{m} \text{~~(conv.~if $\|A-I\|<1$)}.
\end{alignat}
\begin{alignat}{2}
 &\ee^{\log A} = A \text{~~(if $\|A-I\|<1$)},
\quad&
 &\log \ee^X = X \text{~and~} \|\ee^X-1\| < 1 \text{~~(if $\|X\|<\log2$).}
\end{alignat}
\begin{equation}
 \text{Hilbert-Schmidt norm}:~\|X\|^2 := \sum_{i,j}|X_{ij}|^2 = {\Tr X^\dagger X}.
\end{equation}
Properties:
\begin{alignat*}{4}
 \ee^{(X^\TT)} &= (\ee^X)^\TT,
&\qquad
 \ee^{(X^*)} &= (\ee^X)^*,
&\qquad
 (\ee^X)^{-1} &= \ee^{-X},
&\qquad
 \ee^{YXY^{-1}} &= Y\ee^X Y^{-1},
\end{alignat*}
\begin{alignat*}{2}
 \det \exp X &= \exp\Tr X,
&\qquad
 \ee^{(\alpha+\beta)X} &= \ee^{\alpha X}\ee^{\beta X} \text{~for $\alpha, \beta\in \mathbb C$};
\end{alignat*}
Baker-Campbell-Hausdorff:
\begin{align}
  \ee^X Y \ee^{-X}
&= Y + [X, Y] + \frac1{2!}[X, [X, Y]] + \frac1{3!}[X, [X, [X, Y]]] + \cdots = \ee^{[X,]}Y;
\\
  \ee^X \ee^Y \ee^{-X}
&= \sum_{n=0}^\infty\frac{1}{n!}(\ee^X Y \ee^{-X})^n
 = \exp\left(\ee^{[X,]}Y\right);
\\
  \log(\ee^X \ee^Y)
&= X + \int_0^1\!\dd t\, g(\ee^{[X,}\ee^{t[Y,})Y
\qquad\Bigl[
  g(z) = \frac{\log z}{1-z^{-1}} = 1-\sum_{n=1}^{\infty}\frac{(1-z)^n}{n(n+1)};
\quad
g(\ee^y)=\sum_{n=0}^{\infty}\frac{B_ny^n}{n!}
\Bigr]\\
&= X + Y + \frac12[X,Y] + \frac1{12}[X, [X,Y]] - \frac1{12}[Y, [X,Y]] + \cdots
\quad\text{(Baker-Campbell-Hausdorff).}
\end{align}
\begin{align}
   \log(\ee^X\ee^Y)
&=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}\left(\sum_{m,n=0}^{\infty}\frac{X^mY^n}{m!n!}-1\right)^k
&=\sum_{k=1}^\infty
   \sum_{m_1+n_1>0}\cdots\sum_{m_k+n_k>0}\frac{(-1)^{k-1}}{k}
\frac{X^{m_1}Y^{n_1}\cdots X^{m_k}Y^{n_k}}{m_1!n_1!\cdots m_k!n_k!}
\end{align}
\begin{equation}
   \log(\ee^X\ee^Y)=\sum_{k=1}^{\infty}\sum_{m_1+n_1>0}\cdots\sum_{m_k+n_k>0}
\frac{(-1)^{k-1}}{k\sum_{i=1}^{k}(m_i+n_i)}
\frac{
\Bigl([X,\Bigr)^{m_1}
\Bigl([Y,\Bigr)^{n_1}\cdots
\Bigl([X,\Bigr)^{m_k}
\Bigl([Y,\Bigr)^{n_k}]\cdots]
}{m_1!n_1!\cdots m_k!n_k!}
\end{equation}
\hfill with $[X]$ being $X$.
\\
Derivative:
\begin{alignat}{1}
 &\frac{\dd}{\dd t}\ee^{tX} = X\ee^{t X} = \ee^{tX} X\\
 &\ee^{-X(t)}\left(\frac{\dd}{\dd t}\ee^{X(t)}\right) =
    \frac{I-\ee^{-\ad_X}}{\ad_X}\left(\frac{\dd X}{\dd t}\right)
  = X' + \frac{[-X,X']}{2!} + \frac{[-X,[-X,X']]}{3!} + \cdots
\\
 &\left(\frac{\dd}{\dd t}\ee^{X(t)}\right)\ee^{-X(t)}
= X' + \frac{[X,X']}{2!} + \frac{[X,[X,X']]}{3!} + \cdots
\end{alignat}
\hfill where $X'=\dd X/\dd t$ and $\ad_X(Y)=[X,Y]$ is the adjoint action of a Lie algebra. Thus, explicitly,
\begin{alignat}{1}
\frac{\dd}{\dd t}\ee^{aX(t)}
  = \ee^{aX}\left\{\sum_{n=0}^\infty\frac{a^{n+1}}{(n+1)!}\Bigl([-X,\Bigr)^n X']\right\}
  = \left\{\sum_{n=0}^\infty\frac{a^{n+1}}{(n+1)!}\Bigl([X,\Bigr)^n X']\right\}\ee^{aX}
\end{alignat}

\vspace{1em}

\noindent
Component:\quad If matrices $t^a$ satisfies $[t^a,t^b]=\ii f^{abc} t^c$ with totally-antisymmetric $f^{abc}\in\mathbb R$,
\begin{equation}
  \left[\ee^{\theta^at^a} t_b \ee^{-\theta^ct^c}\right]_{ij}
=  \left[\ee^{\theta^a[t^a,}t_b\right]_{ij}
= \left[\ee^{\ii \theta^af^{a}}\right]^{bc} t^c_{ij}
\end{equation}
holds for $\theta^a\in\mathbb C$, where $[f^a]_{bc}=f^{abc}$. \TODO{needs verification, generalization/restriction, and a nice proof or reference.}


\subsection{General unitary matrix}
\begin{equation}
 U_2 =
\pmat{1&0\\0&\ee^{\ii\alpha}}\pmat{\co\theta&\si\theta\\-\si\theta&\co\theta}\pmat{\ee^{\ii\beta}&0\\0&\ee^{\ii\gamma}}
=
\pmat{\phantom{-}
\co\theta\ee^{\ii\beta} & \si\theta\ee^{\ii\gamma}\\
-\si\theta\ee^{\ii(\alpha+\beta)} & \co\theta\ee^{\ii(\alpha+\gamma)}
},\qquad
0\le\theta\le\frac{\pi}2,\quad \alpha,\beta,\gamma\in\mathbb R;
\end{equation}
\begin{align}
 U_3 &=
\pmat{1&&\\&\ee^{\ii a}&\\&&\ee^{\ii b}}
 \pmat{1&&\\&\co{23}&\si{23}\\&-\si{23}&\co{23}}
 \pmat{\co{13}&&\si{13}\ee^{-\ii\delta}\\&1&\\-\si{13}\ee^{\ii\delta}&&\co{13}}
 \pmat{\co{12}&\si{12}&\\-\si{12}&\co{12}&\\&&1}
\pmat{\ee^{\ii c}&&\\&\ee^{\ii d}&\\&&\ee^{\ii e}}
\\&=
\pmat{1&&\\&\ee^{\ii a}&\\&&\ee^{\ii b}}
 \pmat{
 \co{12} \co{13} & \si{12} \co{13} & \si{13} \ee^{-\ii\delta}\\
 -\si{12} \co{23} - \co{12} \si{23} \si{13} \ee^{\ii\delta}& \co{12} \co{23} - \si{12}\si{23}\si{13} \ee^{\ii\delta}& \si{23}\co{13}\\
  \si{12}\si{23} - \co{12} \co{23} \si{13}\ee^{\ii\delta} & -\co{12}\si{23}-\si{12}\co{23}\si{13}\ee^{\ii\delta} & \co{23} \co{13}}
\pmat{\ee^{\ii c}&&\\&\ee^{\ii d}&\\&&\ee^{\ii e}}
\label{eq:GeneralUnitary33}
\end{align}
with $0\le \theta_{ij}\le\pi/2$ and $a,b,c,d,e,\delta\in\mathbb R$ (see, e.g., Ref.~\cite{Rasin:1997pn}).

\begin{minted}{wolfram}
U3 = Dot[
  DiagonalMatrix[Exp[I {0, a, b}]],
  RotationMatrix[\[Theta]23, {-1, 0, 0}],
  DiagonalMatrix[Exp[I {0,0,+\[Delta]}]],
  RotationMatrix[\[Theta]13, {0, 1, 0}],
  DiagonalMatrix[Exp[I {0,0,-\[Delta]}]],
  RotationMatrix[\[Theta]12, {0, 0, -1}],
  DiagonalMatrix[Exp[I {c, d, e}]]
]
\end{minted}


\subsection{Matrix diagonalization}\label{app:diagonalization}
In this section, $\mathbb K=\mathbb{R}$ or $\mathbb{C}$ and $\mathbb U_{\mathbb K}^{n}\subset \mathbb K^{n\times n}$ is the set of the unitary matrices.

\paragraph{Diagonalization}
A matrix $M\in\mathbb K^{n\times n}$ is called diagonalizable if $\exists P$ and $\exists D$ s.t.
\begin{equation}
 M=PDP^{-1};\qquad
 P\in\mathbb{K}^{n\times n},\quad
 D:\text{diagonal matrix}~(D_{ii}\in\mathbb{K}).
\end{equation}
In particular,
\begin{equation}
 \text{$M$ is normal} \stackrel{\text{def}}\iff M^\dagger M = M M^\dagger \iff
 \exists P\in\mathbb{U}_{\mathbb K}^{n} \text{~s.t.~} M=PDP^{-1}.
\end{equation}


\paragraph{Singular value decomposition}
Any $M\in\mathbb{K}^{m\times n}$ can be singular-value decomposed as
\begin{equation}
 M=UDV^\dagger;\qquad
 U\in\mathbb{U}_{\mathbb K}^m,\quad
 V\in\mathbb{U}_{\mathbb K}^n,\quad
 D: \text{non-negative real diagonal matrix}~(D_{ii}\ge0).
\end{equation}
Here, the matrix $U$ ($V$) diagonalizes $MM^\dagger$ ($M^\dagger M$) and $(D_{ii})^2$ are the eigenvalues of $MM^\dagger$ (and $M^\dagger M$).

The calculation on Mathematica is straightforward for this convention:
\begin{minted}{wolfram}
{u, d, v} = SingularValueDecomposition[M]
\end{minted}




\paragraph{Autonne-Takagi factorization}
If $M\in\mathbb{C}^{n\times n}$ is symmetric, it can be decomposed as
\begin{equation}
 M=RDR^\TT;\qquad
 R\in\mathbb{U}_{\mathbb C}^n,\quad
 D: \text{non-negative real diagonal matrix}~(D_{ii}\ge0).
\end{equation}
Real symmetric matrices are normal and thus do not need this factorization; we can apply the above ``diagonalization'' method.

Sample Mathematica code to calculate $\{D,R\}$ (with ordering, if specified) is:
\begin{minted}{wolfram}
AutonneTakagi[M_, order_ : None] := Module[{v0, v, p, ord, R, D},
  ord = If[order === None, Range[Length[M]], order];
  v0 = Eigenvectors[Conjugate[M].M];
  v = Eigenvectors[v0.M.Transpose[v0]].v0; (*resolve degenerate eigenvalues*)
  p = DiagonalMatrix[If[Abs[#] > 0, (#/Abs[#])^(-1/2), 1] & /@ Diagonal[v.M.Transpose[v]]];
  R = ConjugateTranspose[Reverse[p.v][[ord]] // Orthogonalize];
  D = ConjugateTranspose[R].M.Conjugate[R];
  {D, R}];
\end{minted}
\end{document}
